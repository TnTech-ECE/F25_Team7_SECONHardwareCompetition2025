# Project Proposal 

## Introduction and Background  

The IEEE (Institute of Electrical and Electronics Engineers) holds a conference every year for the southeastern region (SoutheastCon – Which is also known as SECON). This conference brings together members of IEEE (Electrical Engineers, Computer Engineers, Computer Scientists, etc.) to discuss research in various areas of each department. At this conference, there are several competitions ranging from circuit design to website design, which include a hardware competition [1]. Tennessee Tech has been entering these competitions yearly, showing up with the skills of students and future engineers. This year, students are tasked with creating an autonomous robot and UAV that are able to communicate with each other to complete a series of tasks. Our score is determined by how many “Astro-Ducks” we rescue, as well as restarting the antennas and launching a satellite within a time limit. This gives students a unique and interesting set of problems to work through, including automated control of a robot and UAV, wireless communication between them, and designing the robots to complete each task [2]. Our team is looking to work with students from the Mechanical Engineering department and several professors to help us along the way. Using their skills to construct the practice arena, help with designing the final robot, and ensure that we are doing the best we can. 



### Specifications and Constraints

The IEEE 2026 SoutheastCon Hardware Competition Ruleset lays out the specifications and constraints for the objective, vehicle design, and board construction. Teams must follow these rules with failure to follow resulting in disqualification from the competition. Below is a list of the specifications and constraints for the competition. 

#### Specifications 


 ##### ***Objective Specifications:*** 

1. Teams may build a micro UAV to work alongside the robot. [2] 
2. Teams must establish communication with Earth via infrared receiver. [2] 
3. Teams will have a maximum of 3 minutes to earn points. [2] 
4. There is a total of 6 total Astro-Ducks to rescue in the course with one duck located at the top of one of the antennas.  [2] 
5. All 6 ducks must be located and returned to the "Lunar Landing Area" on the board. [2] 
6. Teams must establish power to the 4 antennas throughout the course. Power will be restored differently for each antenna. Once power is restored to the antenna, a randomly colored LED will light up (red, blue, green, and purple).[2] 
7. Teams must plant their school flag. The flag must start on the robot and be deployed outside of the starting area [2] 


##### ***Vehicle Specifications:*** 

1. Both the robot and UAV (UAV optional) must be completely autonomous. [2] 
2. Vehicles must fit in the 12" by 12" by 12" starting area. [2] 
3. If the UAV is built, the UAV and robot must start as one unit. The two systems are not required to end as one unit. [2] 
4. The robot must not weigh more than 25 pounds. [2] 
5. The UAV must not weigh more than 0.55 pounds or 250 grams. [2] 
6. The robot may extend its arm or appendages to complete the challenges in the course. [2] 
7. The robot may expand horizontally without restrictions but cannot extend more than 3" outside if the border wall. [2] 
8. The robot may extend vertically, but its height cannot be more than 18" from the playing surface. [2] 
9. The robots may disassemble into as many units are desired but must begin assembled together in a 12" cube. [2] 
10. It is strongly recommended that the robot and the micro UAV include an emergency stop button. [2] 
11. There is no limitation on the hardware development, embedded systems utilized, sensors, or assembly. [2] 
12. The robot and UAV must have a clearly labeled start switch. [2] 
13. Teams are required to handle any accidental interference from other robots or noise sources (Infrared rangefinders for example). [2] 
14. The robot is encouraged to be decorated to the conference theme and display a school logo or mascot, flag, ...etc. [2] 

##### ***Board Specifications:*** 

1. The competition arena is rectangular sheet of plywood with exterior size of 4' x 8' and 5mm" thickness. This sheet will be attached to the border walls using 1" cabinet screws. [2] 
2. The arena border walls will be assembled with three 1” x 8” x 8’ square edged Unfinished Whitewood Boards. [2] 
3. The arena will be supported by utilizing two 1” x 6” x 8’ square edged Unfinished Whitewood Board and 1-1/4" interior wood screws. [2] 
4. A single stabilizing joint will be placed between the center 2 legs of the arena board and will be assembled with one 1” x 6” x 6’ square edged Unfinished Whitewood Board and 1-1/4". [2] 
5. Two starting white LED bars will be placed on top of the arena wall, one on each side of the 12”x12” starting area. [2] 
6. The Earth arm will utilize a single 2” x 2” x 8’ wood post. [2] 
7. The Crater will be 2’ in diameter with a downward slope into an 8” diameter flat area. It will be fully 3D printed and affixed to the playing field. It will also be supported by a sheet of plywood attached underneath the playing field. [2] 
8. The competition playing field will be divided into 4 main areas. The areas will feature 1 antenna and 1 Astro-Duck in areas 1, 2 and 4, and 3 Astro-Ducks in area 3. Six Astro-Ducks in total will be distributed across the playing field. [2] 
9. Area #1 is located in the lower left quadrant of the arena and accounts for 25% of the playing field. Area #2 is located in the upper left quadrant of the arena and accounts for 25% of the playing field. Area #3 is the right half of the arena which accounts for 40% of the playing field. Area #4 is on the right side of the arena inside Area #3. This area is where the crater is which accounts for 10% of the playing field. [2] 
10. All Astro-Duck placements will be placed face up and not within 2" of the separation line between zones. [2] 
11. There will be a total of 4 antennas placed on the board with one being in each arena. Each antenna will be different designs with the base remaining the same. [2] 
12. Antenna #1 will be located in Area #2 with a button task. Antenna #2 will be located in Area #3 with a crank task. Antenna #3 will be located in Area #4 with a pressure plate task. Antenna #4 will be located in Area #1 with a keypad task. [2] 
13. The Earth will be 3D printed using grey filament with all electronic parts besides the IR receiver placed inside. [2] 

 

#### Constraints 

##### ***Objective Constraints:*** 

1. Teams will have a maximum of 3 minutes to earn points. [2] 
2. Points will be lost every time the robot or micro UAV has an unintentional collision with the antennas. [2] 
3. Points will be lost for each improper antenna LED identification sent to earth. [2] 

 
##### ***Vehicle Constraints:*** 

1. All vehicles must be completely autonomous. [2]  
2. All vehicles when combined must fit inside the 12" by 12" by 12" starting area. [2] 
3. The robots must begin as one unit when starting. [2] 
4. The robot must not weigh more than 25 pounds. [2] 
5. The UAV must not weigh more than 0.55 pounds (250 grams). [2] 
6. A robot with appendages must fold/constrict and otherwise fit within the 12” cube robot size restriction before a run begins. [2] 
7. The robot may expand horizontally without any restrictions other than it cannot extend more than 3” outside of the border wall of the playing area. [2] 
8. The robot may expand vertically, but its height must not exceed 18” (not counting the micro UAV) from the playing surface. [2] 
9. The robots may disassemble into as many units as desired, but they must begin assembled together in a 12” cube. [2] 
10. All units, particularly flying units, must not move outside of the netted playing field 
11. No explosive, pyrotechnic, toxic, or corrosive materials. Flammable liquids or gasses are prohibited. [2] 
12. No modifications including padding will be allowed to or around the game board and floor. [2] 
13. The robot shall not present any danger to the judges, spectators, playing arena, or area surrounding the arena [2] 

##### ***IEEE Standard Constraints:*** 

1. Electrical Safety & Wiring 
    - IEEE 602 – National Electrical Safety Code (NESC) [3] 
    - IEEE 1184 – Electrical System for Mobile Units [4] 
2. Wireless Communication 
    - IEEE 802.11 for Wi-Fi [5] 
    - IEEE 802.15.1 for Bluetooth [6] 
3. Battery & Energy Safety 
    - IEEE 1725 – Rechargeable Batteries for Portable Devices [7] 
    - IEEE 1625 – Rechargeable Battery Systems for Portable Computing [8] 
4. Reliability 
    - IEEE 1228 – Software Safety Plans [9] 
    - IEEE 1012 – Verification and Validation [22] 
5. Ethical & Operational Standards 
    - IEEE Code of Ethics [23] 
    - IEEE 12207 – Software Lifecycle Processes [24] [25] 


## Formulating the Problem 

There is no complete off-the-shelf solution that can be purchased to meet the specifications and constraints listed above. If there were, they would likely be too expensive for our limited budget and defeat the purpose of the design competition. The team does have access to the robot constructed by the previous team, as well as the documentation for it. The team shall utilize those resources in order to reduce the cost of potential parts and development time by reusing the previous robot’s code and components whenever possible. Despite having access to these resources, the team will have to overcome a unique set of challenges as defined below. These challenges are drawn from the specifications and contains as listed above [2]. 


##### OBJECT/COLOR DETECTION AND AREA IDENTIFICATION 

The robot must be able to identify and categorize different classes of objects. These objects include: the astro ducks, the antenna towers, and the four different tasks located on each antenna tower. The robot must be able to identify the astro ducks in order for the robot to be able to collect and dispense them in the proper location. The robot must be able to identify the antenna towers in order to avoid colliding with them and to navigate to them to complete the task located on the front. The robot must be able to identify the given task located on the antenna tower in order to perform the correct action needed to complete it. 

The robot or UAV must also be able to correctly identify the different colors of the antenna tower LEDs in order for the UAV to transmit them back to earth. The robot or UAV must also be able to identify which area the LED was located in. 

##### ROBOT AND UAV NAVIGATION 

The robot and UAV must be able to navigate autonomously. The robot must be able to navigate to the locations of the astro ducks, the antenna towers, and the lunar landing zone in an efficient manner. The robot must be able to navigate the playing board without colliding into the game board walls or antenna towers. The UAV must be able to fly within the bounds of the game board. The UAV must be able to navigate to the correct position in order to transmit the LED data to the Earth. 

##### ROBOT AND UAV CONTROL 

The robot and the UAV must have a software architecture and algorithms that can handle the computationally heavy tasks of navigation, object identification, object manipulation, and data transmission. It will also need to be able to handle the low-level control of the robot’s motors in order to complete navigational and object manipulation tasks. 

##### WIRELESS TRANSMISION OF DATA 

The robot must be able to communicate with the UAV in order to complete the needed navigation and Identification tasks as described above. The UAV must be able to transmit the color and location of the LEDs located on each antenna tower. 

##### ROBOT AND UAV SAFETY 

It is highly encouraged to include safety features on both the robot and the UAV, however, the team shall treat these recommendations as strict requirements. Both the robot and the UAV must have a mechanism to stop operations in the event of an emergency condition such as loss of communication signals, a severe collision, catastrophic failure, and other such instances.  


## Survey of Existing Solutions 

##### GAME BOARD 

The previous year’s team had constructed the game board that was used for their completion. The team shall utilize this pre-exciting board; however, it will need to be modified. Such modifications include adding an additional post to attach the mock earth, adding the crater, adding antenna towers, and removing the structure in the middle of the board [2]. 

##### ROBOT NAVIGATION 

Navigation process requires four key components.  

Firstly, the robot must be able to perceive the environment around it [10]. This can be done with the use of sensors such as inertial measurement units (IMUs), LiDAR sensors, and robot-mounted cameras. IMU’s can be used to capture both position and orientation data [11], while LiDAR sensors can be used for accurate range finding and positioning [12]. Through the use of image processing software, cameras can also be a useful tool for navigation. They can be used for color and object depth detection, which can be used for environment mapping or object detection and avoidance [11]. 

Secondly, the robot must utilize a method for localization, which is the process of determining where the robot is in its environment [10] [13]. Localization can be separated into two types: local (relative) and global (absolute) navigation. Local localization refers to knowing a robot’s position relative to its starting position, while global localization refers to knowing the robot’s absolute position in its environment, regardless of its starting position [11]. The team shall utilize both of these types of localization. Relative localization can be achieved by the use of IMUs and LiDAR sensors [11], and the team will use relative localization in order to develop an object avoidance strategy. Absolute navigation can be achieved by the use of an off-board camera, in this case a UAV-mounted camera, that can be used to build a virtual map for the robot to navigate within. 

Being able to map the environment that the robot inhabits is an important part of localization. A map is used to detail the physical space of the robot’s environment, which can be used to help plan efficient travel routes. Simultaneous Localization and Mapping (SLAM) is a common method that is used to create maps for autonomous navigation [10] [14]. SLAM can be implemented in different forms, utilizing a single group of sensors are a mixture of sensors to build an accurate representation of the robot’s physical environment [10] [14]. The camera mounted on the UAV can be used to collect the needed data to help build a SLAM map. Lastly, the use of Path planning algorithms and Control theory rounds out the requirements for autonomous navigation [10]. 

##### MASTER CONTROL 

The robot must have hardware and software that is capable of running computationally heavy processes such as navigational mapping and pathfinding, and object detection. These tasks will most likely require the use of machine learning and computer vision techniques, which will require a hardware controller with the appropriate amount of computing power to run those processes efficiently. The NVIDIA Jetson Nano is a microcontroller that is designed to handle AI loads and has built-in hardware support for devices such as cameras and LiDAR sensors [15]. It also has the ability to run operating systems such as Linux and the Robot Operating System (ROS). NVIDIA also has a ROS package that is built to provide a framework for implementing AI tools such as object detection and manipulation [16]. ROS also has a set of native tools that can be utilized for mapping and navigation as well [10]. 

The Jetson Nano was also the controller of choice of the previous design team, however, they opted to develop their own software architecture for handling their robot’s system and event processing. Most of this programming could be reused and added onto in order to accomplish the additional challenges of this year’s competition.  

During the design phase of the project, the team shall take into consideration whether or not to maintain and continue developing the previously established software architecture, or to replace it with a ROS-focused approach. In either approach, the team shall be able to utilize other tools in conjunction with the previous architecture or ROS, such as OpenCV. OpenCV is an open-source library of various machine learning and computer vision algorithms and tools for a wide range of applications [17].  

##### WIRELESS COMMUNICATION 

The team shall use Wi-Fi to establish wireless communication between the GR and the micro UAV. The RPi’s shall be placed on the robot and UAV. The connection will be implemented using Raspberry PI (RPi) to establish bi-directional communication. Both the GR and the UAV shall be connected to the same Local Area Network (LAN). The GR will act as a wireless access point and connect to the UAV which will be the client. TCP or UDP sockets will then be used to allow the GR and UAV to communicate by sharing their IP address. This shall allow the team to use sensor feedback, telemetry, and commands. Also allows for the broadcast of video between the GR and UAV.  The GR and UAV shall also be capable of sharing GPS. Team shall get two Raspberry Pi’s and micro SD cards and install raspberry Pi OS on the SD cards. The team shall use Python to code the Raspberry Pi and run the server on the GR and UAV. They shall then exchange messages via from the GR and UAV.  [18][19] 

##### OBJECT/LINE DETECTION 

The robot must be able to detect the objects in its environment in order to avoid collisions and to interact with them properly. This is a task that will require the use of computer vision and machine learning techniques in order to properly identify the different objects the robot will interact with. The team’s strategy will be similar to a solution designed by a previous team [20], with the exception of needing to train the computer vision model with more objects, as listed in the previous section. Another exception to the previous design will be how the game board lines will be interoperated. The game board lines for this year’s competition will not be used as a navigational path, but rather as borders that will segment the game board into the different areas as defined in the ruleset [2]. The painted sections on the game board can also be used to segment the board into the different areas. 

##### UNKNOWN FACTORS 

There is a set of challenges that have a set of unknown factors that will need to be further developed as the design phase begins. These include: The design of the robot body, the location of electronic equipment on the robot, the drive system that will be used for the robot, and the types of actuators/end effectors that will be used to complete the various tasks as listed in the specifications section. This is by no means an exhaustive list, but it includes the design issues that were the most apparent to the team. The team shall work closely with their mechanical engineering counterpart in order to design an effective solution for these design problems. 

Another challenge that the team will face involves the control and utilization of the UAV. The final solution for the UAV will look different based on whether or not the team opts to use an off-the-shelf solution for the UAV, or build one from scratch. An off-the-shelf UAV can come prepackaged with useful features such as high-resolution cameras, built-in safety features, and the ability to conduct autonomous waypoint missions. However, the main issue comes from the potential lack of control that the robot can have over those features. Whether or not the UAV can be controlled by the robot’s master controller also rises when considering off-the-shelf solutions. The team can instead build a drone from scratch using a variety of Do It Yourself and development kits [2] [21], however, that would add a significant workload to the project. The team would be able to customize the UAV to fit the needs of the project if the team is able to abide by the UAV restraints listed previously. The team shall consider these tradeoffs once the design phase begins. 


## Measures of Success 

The project’s success shall be measured by the accuracy and precision of the tasks completed. The accuracy and precision of each task is defined below. 

##### Navigating the course: 

  - The team shall conduct 3 course runs without obstacles and 3 course runs with obstacles.  
  - A successful course run with and without obstacles shall be defined as navigating the course with the GR and UAV for one minute without any collisions with the edges of the course and the Earth or antenna. [2] 

##### Collection of the ducks: 

  - The team shall then conduct 10 course runs with obstacles where the ducks are collected. The team shall define accuracy as the number of ducks collected in a trial. The max accuracy shall be defined as the collection of ALL 6 ducks. 
  - The collection of the ducks shall be done using the communication features between the GR and UAV. The team shall successfully identify the location of all the Ducks using the UAV and communicate the location to the GR. 
  - The team shall conduct 5 trial runs where they return all the ducks to the Lunar Landing Area with an accuracy of 5 out of 6 ducks being placed in the correct location. 
  - The team shall consider a complete trial as the collection of the Ducks, the identification of the LED colors on the antennas, the communication of the LED colors to the Earth, and the planting of the flag.  
  - A complete trial of Max success will be defined as collecting all six ducks and correctly identifying and relaying all three LED colors, as well as dropping the flag outside of the designated course area within 3 minutes. 

##### Antenna identification: 

  - The UAV will be used to correctly identify the colors of the LEDs on the antennas and communicate these colors to the GR. 
  - The team shall conduct 10 trial runs using the GR to correctly identify the LED color on the antenna and send it to Earth. The max accuracy shall be defined as the correct LED color identification of ALL 3 antennas. The team shall complete the trial runs with a max accuracy of 8 out of 10 (max accuracy on 8 trials). 
  - IEEE will define success as proper antenna LED identification sent to Earth. [2] 

##### Antenna restoration: 

  - The team will correctly restore power to the antennas via the GR. 
  - The team will restore power to Antenna 1 by pressing the button on the side of the antenna three times. 
  - The team will restore power to antenna 2 by rotating a crank 450° clockwise or counterclockwise. 
  - The team will restore power to antenna 3 by removing the duck from the pressure plate. 
  - The team will restore power to antenna 4 by typing the number 73738# into the keypad. [2] 

##### GR and UAV: 

  - The team shall construct the GR and the UAV to fit within a 12 by 12 by 12 cubic inch space when they are placed together. 
  - The team shall construct the UAV to not exceed 249 g [2] 
  - Event that the accuracy metric isn’t met: 
  - In the event that the stated accuracies for the trial runs are not met, the team shall analyze and review the cause of error, make adjustments to the GR or UAV where needed and conduct the trials again until they reach the accuracy metric. [2] 

##### IEEE shall measure our success via: 

  - 10 points - the robot leaving the start area 

  - 10 points - the robot planting the flag outside of the start area 

  - 15-60 points - turning each antenna on 

  - 5-30 points - placing the Astro-duck  in the Lunar Landing Area 

  - 20 points - first connection to the Earth 

  - 15-30 or 60-120 points - proper antenna LED identification, displayed LED on the robot, and sending them to Earth 

  - 15 points - the robot ending the round in the starting area 

  - 20 points - the robot successfully entering and exiting the crater (which is defined as a portion of the drive mechanism touching the crater line) 

  - 35 points - the robot completing one full lap around the crater with the moving mechanism touching the crater below the crater line (3 inches below the rim of the crater) 

  - 30 points - the launch of the UAV which features the robot completely exiting the star area and the UAV moving 15 in horizontally and 15 in vertically from the robot 

  - 50 points - retrieval of the UAV ( which is to successfully land on the robot and remain on the robot after a successful launch) 

  - 15 points -  the robot starting using a white LED start bar without human touch 

  - 15 points - participation in the student design competition 

  - 370/430 Max points - 370 for antenna identification on the robot only and 430 when antenna identification sent to earth (or sent to earth and displayed on robot)

 

##### IEEE will measure our failure via: 

  - 3 points will be lost for each unintentional collision from the UAV or the robot with the antennas with a max of 30 points 

  - 15 points will be lost for improper LED identification sent to Earth with a Max of 120 points [2] 



## Resources  

Our team will leverage a wide range of resources to ensure a successful design, build, and competition run: 

**Human Resources** – Our project is supported by our faculty advisor, Dr. Canfield, who will provide technical oversight and design feedback, as well as our customer/sponsor, Dr. Johnson, who ensures alignment with the competition’s objectives. Each team member contributes specialized skills in mechanical design, electronics, printed circuit board design, and software development. We also benefit from the experience of Dakota, a previous year’s contestant, who offers valuable insights into competition strategy and lessons learned from prior participation. Additionally, Dr. Tristan Hill will provide guidance in robot programming through his expertise in the Robot Operating System (ROS), further strengthening our software development efforts. 

**Facilities & Support** – We will utilize the Capstone Lab for prototyping, fabrication, and testing, which includes access to 3D printing, soldering equipment, and workspace. Additionally, the official competition will provide practice boards, a hardware room, and staging areas that will serve as critical resources for final testing and preparation. 

**Material & Hardware Resources** – The project relies on components outlined in the official Bill of Materials (BOM), including arena construction supplies (wood, screws, paints), mechanical elements (PVC frames, netting), and 3D-printed parts such as craters, antennas, and the Earth module. Electronics such as Arduino boards, LEDs, sensors, batteries, and wiring kits will form the backbone of the robot and UAV system. We will also explore lightweight UAV options that comply with competition weight restrictions. In addition to the current year’s documentation, we have access to previous years’ BOMs and IEEE competition resources, which provide valuable reference points for component selection, sourcing, and design improvements 

**Documentation & Knowledge Resources** – The official competition ruleset, along with the provided CAD models, wiring diagrams, and assembly guides, will serve as essential references throughout the design process. In addition, we have access to KiCAD for schematic and PCB design, enabling us to develop and simulate custom circuit layouts. Our team also has access to NEC and IEEE standards, ensuring that our designs meet established electrical, safety, and professional engineering guidelines. Together, these resources ensure that our work aligns with the technical and operational requirements of the SoutheastCon Hardware Competition. 


### Bugdet

**Robot BOM:**

|Item|Cost per Item|Quantity|Total Cost for Item|
| :- | :- | :- | :- |
|Ultrasonic Sensor|~$5|5|$25|
|LiDAR Sensors|~$100|1|$100|
|Lithium Battery|~$62|3|~$190|
|Mircocontroller|~$30|2|~$60|
|Motor Drivers|~$25|2|~$50|
|Brushed Motors|~$30|2|~$60|
|Encoder|~$10|2|$20|
|IMU|~$8|1|~$8|
|Power Distribution PCB|~$20|1|~$20|
|Spare Buck|~$5|1|~$5|
|Total|||~$538|

**UAV BOM:**

|Item|Cost Per Iteam|Quantity|Total Cost for Item|
| :- | :- | :- | :- |
|Brushless Motors|~$14|4|~$56|
|AIO FC + ESC|~$70|1|~$70|
|Propellors|~$3|4|~$12|
|Lithium Battery|~$20|1|~$20|
|Micro GPS|~$25|1|~$25|
|Forward ToF Sensor|~$15|1|~$15|
|Inline Power Switch|~$8|1|~$8|
|Total|||~$206|

**Shared BOM:**

|Item|Cost Per Iteam|Quantity|Total Cost for Item|
| :- | :- | :- | :- |
|Lithium Battery Charger|~$100|1|~$100|
|Silicon Wire Kit|~$20|1|~$20|
|Heat-Shrink Tubing|~$10|1|~$10|
|Connectors Kit|~$40|1|~$40|
|E-Stop Switches|~$10|2|~$20|
|Assorted Resistors|~$10|1|~$10|
|Assorted LEDs|~$5|1|~$5|
|Buzzers|~$5|1|~$5|
|Total|||~$210|

**Final BOM Cost:** ~$954


### Personal 

##### Skills Present: 

  - Trevor Snyder - Electrical Engineering major. Proficient in C++, MATLAB, LtSpice, Digital Systems, and Circuit Design. Some familiarity in machine learning, PLCs, C, Assembly, and Embedded Systems. 

  - Angela Nde – Electrical Engineering major. Proficient in digital logic and circuitry, technical writing, professional presentation, and power. Some familiarity in Python, Microcontrollers, and controls. 

  - John Land 

  - Atra-Niese - Electrical Engineering Major. Proficient or experienced in C++, Matlab, LtSpice, Assembly, Microcontrollers, Shapr3D (3-D Design) and Digital systems

  - Aiden Mullins – Electrical Engineering with a concentration in mechatronics. Proficient in C++, Assembly, Control Systems, and Arduino IDE. 

  - Jane Vassar – Electrical Engineering/Mechatronics. Proficient with C/C++, MATLAB, Circuits, Microcontrollers, Mechanical/Electrical CAD, Control Systems, System Integration. Has been exposed to mechanical design concepts. 

##### Skills Needed: 

  - Trevor Snyder - CAD software, wireless communication, CubeIDE/STM32 HAL, and Autopilot firmware 

  - Angela Nde – MATLAB, wireless communication, signal processing, and embedded systems 

  - John Land - CAD, Controls Systems, Interface Implementation/Design, Networking  

  - Atra-Niese - Wireless communication, Control Systems Analysis, Robotic/UAV Automation 

  - Aiden Mullins – Networking, Data Processing 

  - Jane Vassar – Control Systems, Programming for Robotics, Arduino programing, wireless communication, building/using AI/ML/CV tools



The team's supervisor is Dr. Stephen Canfield Ph.D. He was chosen as the project’s advisor for his nationally recognized expertise in robotics and autonomous systems.  

The team’s instructor is Dr. Christopher Johnson and will be our customer. 


### Timeline

![image](https://github.com/TnTech-ECE/F25_Team7_SECONHardwareCompetition2025/blob/Project_Proposal/Reports/Poster%20Template/Images/GnattChart1.png)

The Gantt Chart is a project management tool that visually organizes the project’s timeline, ensuring effective allocation of resources and timely completion of different tasks.


## Specific Implications

The implementation of the UAV shall provide essential information necessary to complete the objectives required within the three-minute mission time limit. The UAV provides an aerial perspective that the robot cannot achieve on its own, conveying information such as location tracking and arena layout mapping that are crucial to the operation of the ground unit robot.  

The information the UAV will transfer to the robot shall allow for accurate collection of the Astro-ducks around the arena and successfully deliver them to the lunar landing-site. More precise navigation will also enhance object detection and support the successful avoidance of obstacles, including collision with the Earth, antennas, or boundaries of the arena. This will ensure safer and more efficient task completion.  

In addition to navigation, the UAV shall also utilize its aerial data to accurately identify and communicate LED colors displayed on the antennas. The colors identified shall then be transmitted to Earth for flag identification. As the identification and communication of antenna location and color directly corresponds to points awarded, the UAV is necessary for successful operation for the customer.  

Overall, the UAV shall provide irreplaceable information regarding antenna location, duck rescue, and accurate color identification, ensuring the successful operation of UAV-robot integrated system. Incorporating both ground and aerial benefits will increase the speed, accuracy, autonomy, and overall efficiency of the design and the missions’ success. 


## Broader Implications, Ethics, and Responsibility as Engineers 

Although this UAV-robot integrated system was created specifically for the SECON competition, its design, components, and capabilities have broader applications. Aerial-ground systems can be utilized for future disaster responses, large scale tracking and inspection tasks, and long-range data transmission. These are the same principles demonstrated in the SECON mission requirements. By showcasing these capabilities, the design highlights the importance of engineering roles and educational programs in advancing the efficiency and adoption of aerial-ground systems in society.  

Despite the UAV being an extremely efficient form of information collection and transmission, there are potential risks that need to be addressed. Collison with people, obstructions, and other equipment can be mitigated through obstacle detection and use of lightweight, smooth materials. The UAV shall also include a safe-landing protocol that activates when the battery falls below a critical threshold, overheats, or draws excessive current. These measures will ensure safe operation during the mission and in environments where people or equipment are present.  

Environmental responsibility is a key factor in the system’s design. Equipment is consciously selected with environmental safety in mind.  Proper disposal methods shall be followed to reduce environmental impact without compromising performance.  

The design shall uphold professional standards by acknowledging accountability of both the technical and ethical responsibilities of the project. This includes prioritizing safety, sustainability, and transparent communication of design strengths and limitations, which benefits the immediate spectators, equipment, and judges of the arena. This also includes contributing to the lasting impacts of future designs and applications of aerial-ground systems and technologies.   


## References


[1]“Student Competitions – IEEE SoutheastCon 2023.” https://ieeesoutheastcon.org/student-competitions/ 

[2] IEEE SoutheastCon, 2026 IEEE SoutheastCon Hardware Competition Ruleset, Final Version, Aug. 15, 2025. 

[3] "2023 National Electrical Safety Code (NESC®) Handbook," in 2023 National Electrical Safety Code (NESC) Handbook , vol., no., pp.1-776, 1 Aug. 2022, doi: 10.1109/IEEESTD.2022.9843875. 

‌[4] "IEEE Guide for Batteries for Uninterruptible Power Supply Systems," in IEEE Std 1184-2022 (Revision of IEEE Std 1184-2006) , vol., no., pp.1-110, 16 May 2022, doi: 10.1109/IEEESTD.2022.9774336. 

[5] "IEEE Standard for Information Technology -- Telecommunications and Information Exchange Between Systems Local and Metropolitan Area Networks -- Specific Requirements - Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications - Amendment 4: Enhancements for Wireless LAN Sensing," in IEEE Std 802.11bf-2025 (Amendment to IEEE 802.11-2024, as amended by IEEE 802.11bh-2024, IEEE 802.11be-2024, and IEEE 802.11bk-2025) , vol., no., pp.1-228, 26 Sept. 2025, doi: 10.1109/IEEESTD.2025.11184214 

[6] "IEEE Standard for Low‐Rate Wireless Networks," in IEEE Std 802.15.4-2024 (Revision of IEEE Std 802.15.4-2020) , vol., no., pp.1-967, 12 Dec. 2024, doi: 10.1109/IEEESTD.2024.10794632 

[7] "IEEE Standard for Rechargeable Batteries for Mobile Phones," in IEEE Std 1725-2021 , vol., no., pp.1-80, 23 Aug. 2021, doi: 10.1109/IEEESTD.2021.9514813. 

[8] "IEEE Standard for Rechargable Batteries for Portable Computing," in IEEE Std 1625-2004 , vol., no., pp.0_1-, 28 May 2004, doi: 10.1109/IEEESTD.2004.243226. 

[9] "IEEE Standard for Software Safety Plans," in IEEE Std 1228-1994 , vol., no., pp.1-24, 30 Nov. 1993, doi: 10.1109/IEEESTD.1993.9097571. 

[10] “Autonomous Navigation - an overview | ScienceDirect Topics,” www.sciencedirect.com. https://www.sciencedirect.com/topics/computer-science/autonomous-navigation 

[11] “Leo Rover Blog - Top common ways to localize a mobile robot,” Leorover.tech, 2023. https://www.leorover.tech/post/top-common-ways-to-localize-a-mobile-robot 

[12] A. Szczepaniak, “Leo Rover Blog - How is LiDAR used in Robotic Navigation? Pros and Cons,” www.leorover.tech, Jan. 16, 2023. https://www.leorover.tech/post/how-is-lidar-used-in-robotic-navigation-pros-and-cons 

[13] Engra, “Autonomous navigation and mobile robots | Robotnik ®,” Robotnik, Jun. 17, 2025. https://robotnik.eu/autonomous-navigation-and-mobile-robots/ (accessed Oct. 01, 2025). 

[14] R. Kala, “Visual SLAM, planning, and control,” Elsevier eBooks, pp. 103–150, Jan. 2024, doi: https://doi.org/10.1016/b978-0-443-18908-1.00007-8. 

[15] NVIDIA, “NVIDIA jetson nano,” NVIDIA. https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/product-development/ 

‌[16] “Isaac ROS,” NVIDIA Developer. https://developer.nvidia.com/isaac/ros 

‌[17] OpenCV, “About OpenCV,” OpenCV, 2018. https://opencv.org/about/ 

‌[18] wireless[1] “Configuration – raspberry pi documentation,” Raspberry Pi, https://www.raspberrypi.com/documentation/computers/configuration.html (accessed Oct. 2, 2025).  

[19] “Wiki,” ros.org, http://wiki.ros.org/ROS/NetworkSetup (accessed Oct. 2, 2025). 

[20] TnTech-ECE, “F24_Team1_SECON/Reports/Detailed-Design-Camera.md at main · TnTech-ECE/F24_Team1_SECON,” GitHub, 2025. https://github.com/TnTech-ECE/F24_Team1_SECON/blob/main/Reports/Detailed-Design-Camera.md (accessed Oct. 01, 2025). 

[21]“Payload SDK,” Dji.com, 2025. https://developer.dji.com/doc/payload-sdk-tutorial/en/basic-introduction/whats-psdk.html (accessed Oct. 01, 2025). 

[22] "IEEE Standard for System, Software, and Hardware Verification and Validation," in IEEE Std 1012-2024 (Revision of IEEE Std 1012-2016) , vol., no., pp.1-309, 22 Aug. 2025, doi: 10.1109/IEEESTD.2025.11134780 

[23] IEEE Code of Ethics, IEEE, 2020. [Online]. Available: https://www.ieee.org/about/corporate/governance/p7-8.html 

[24] "ISO/IEC/IEEE International Standard - Systems and software engineering -- Software life cycle processes," in ISO/IEC/IEEE 12207:2017(E) First edition 2017-11 , vol., no., pp.1-157, 15 Nov. 2017, doi: 10.1109/IEEESTD.2017.8100771. 

[25] "ISO/IEC/IEEE International Standard - Systems and software engineering--System life cycle processes," in ISO/IEC/IEEE 15288:2023(E) , vol., no., pp.1-128, 16 May 2023, doi: 10.1109/IEEESTD.2023.10123367. 

[26] IEEE, IEEE Code of Ethics, IEEE, [Online]. Available: https://www.ieee.org/content/dam/ieee-org/ieee/web/org/about/corporate/ieee-code-of-ethics.pdf 

[27] Author(s), “Title of Article,” International Journal of Aviation, Aeronautics, and Aerospace, vol. X, no. Y, pp. A–B, Year. [Online]. Available: https://commons.erau.edu/cgi/viewcontent.cgi?article=1503&context=ijaaa 


 

## Statement of Contributions 

 

  - Jane Vassar – Worked on the “Formulating the Problem” and the “Survey of Existing solutions” section. Researched the implementation of the previous year’s robot and researched and documented potential solutions for this team’s project. 

  - Angela Nde – Worked on the “Specific Implications” and the “Broader Implications, Ethics, and Responsibility as Engineers” section. Outlined the benefits and professional responsibilities of utilizing a UAV-robot system. 

  - John Land - Worked on the “Resources” section. 

  - Trevor Snyder – Worked on the “Specifications and Constraints” and “Budget” sections 

  - Aiden Mullins – Worked on the “Intro & Background” section

  - Atra-Niese - Worked on the “Measures of Success” and “Wireless Communication” section under “Survey of Existing Solutions”. Defined the expectations of IEEE and University of Alabama Huntsville (UAH) as well as the metrics used to define success. Detailed the establishment of wireless communication between the UAV and robot. 








